{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9829787-5e53-49f4-b4d2-219dc306ca80",
   "metadata": {},
   "source": [
    "## File Organization (Python 3.12.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a707d-69ee-4803-b1a3-7b7eeba81686",
   "metadata": {},
   "source": [
    "To run the code create a folder. Inside that folder put preprocessing.ipynb. Create folders data > dataset > Free . Within the Free folder, put the unzipped IXI-PD, IXI-T1, and IXI-T2 folders. Return to the preprocessing file and run the code."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1617f63f-96e6-45d8-849d-fe08b5bea207",
   "metadata": {},
   "source": [
    "Pre-Processing.ipynb\n",
    "data/\n",
    "    dataset/\n",
    "        Free/\n",
    "            IXI-[Modality]\n",
    "                training\n",
    "                    ([Modality] images)\n",
    "                validation\n",
    "                    ([Modality] images)\n",
    "                testing\n",
    "                    ([Modality] images)\n",
    "                \n",
    "        noise_{noise_level}/\n",
    "            testing\n",
    "                IXI-[Modality]/\n",
    "            validation\n",
    "                IXI-[Modality]/\n",
    "            training\n",
    "                IXI-[Modality]/\n",
    "    patchs32_32_{noise_level}/\n",
    "        free/\n",
    "            testing\n",
    "                IXI-[Modality]/\n",
    "            validation\n",
    "                IXI-[Modality]/\n",
    "            training\n",
    "                IXI-[Modality]/\n",
    "        noised/\n",
    "            testing\n",
    "                IXI-[Modality]/\n",
    "            validation\n",
    "                IXI-[Modality]/\n",
    "            training\n",
    "                IXI-[Modality]/\n",
    "    mixdata/\n",
    "        free/\n",
    "            IXI-[Modality]\n",
    "                testing\n",
    "                    ([Modality] images)\n",
    "                validation\n",
    "                    ([Modality] images)\n",
    "                training\n",
    "                    ([Modality] images)\n",
    "        noised/\n",
    "            IXI-[Modality]\n",
    "                testing\n",
    "                    ([Modality] images)\n",
    "                validation\n",
    "                    ([Modality] images)\n",
    "                training\n",
    "                    ([Modality] images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2bc9a9-33e5-4dfe-bd43-19cfeb38b732",
   "metadata": {},
   "source": [
    "## Import The Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d2be6-cf48-4b00-bfbc-e1b52eab4fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib # read MRI images\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm #time module progress bar\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import shutil # moving files\n",
    "import json  # For saving patch names and mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fecd4a1-e475-47b1-83e0-b2ce6726b866",
   "metadata": {},
   "source": [
    "## HammerSmith Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e77713d-ffd2-4dfc-8364-29f080d46771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hammer_mri(num1,num2,num3):\n",
    "    base_dir = \"./data/dataset/Free/\"\n",
    "    mods = [\"IXI-T1\",\"IXI-T2\",\"IXI-PD\"]  # Modalities\n",
    "    total_num = num1 + num2 + num3 # total number of files\n",
    "    \n",
    "    for x in mods:\n",
    "        input_dir = os.path.join(base_dir, x)\n",
    "\n",
    "        for f in tqdm(os.listdir(input_dir),desc=f\"Processing {x} - Filtering Hammersmith Files\"):\n",
    "            if 'HH' not in f:\n",
    "                os.remove(os.path.join(base_dir, x,f))\n",
    "\n",
    " \n",
    "        sorted_files = sorted(os.listdir(input_dir))\n",
    "        random.shuffle(sorted_files)\n",
    "        count = 0\n",
    "        for f in tqdm(sorted_files,desc=f\"Processing {x} - Limiting Count to {total_num} files\"):\n",
    "            count +=1\n",
    "            if count > total_num:\n",
    "                os.remove(os.path.join(base_dir,x,f))\n",
    "        z = 0\n",
    "        for f in tqdm(sorted_files,desc=f\"Processing {x} - Sorting into Respective Sets\"):\n",
    "            original_file_path = os.path.join(base_dir,x,f)\n",
    "            training_path = os.path.join(base_dir, x,\"training\")\n",
    "            valid_path = os.path.join(base_dir, x,\"validation\")\n",
    "            testing_path = os.path.join(base_dir, x,\"testing\")\n",
    "            \n",
    "            if not os.path.exists(training_path):\n",
    "                os.makedirs(training_path)\n",
    "            if not os.path.exists(valid_path):\n",
    "                os.makedirs(valid_path)\n",
    "            if not os.path.exists(testing_path):\n",
    "                os.makedirs(testing_path)\n",
    "            z+=1\n",
    "            if z <= num1:\n",
    "                shutil.move(original_file_path,training_path)\n",
    "            elif num1 < z <= num1 + num2:\n",
    "                shutil.move(original_file_path,valid_path)\n",
    "            elif num1 + num2 <= z <= total_num:\n",
    "                shutil.move(original_file_path,testing_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0232d8dc-7dd0-4e12-a44d-962470f93d5d",
   "metadata": {},
   "source": [
    "## 6 Image Deep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168bf58a-a03c-4687-81d9-f575295d131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mid_slices():\n",
    "    base_dir = \"./data/dataset/Free/\"\n",
    "    mods = [\"IXI-T1\", \"IXI-T2\", \"IXI-PD\"]  # Modalities\n",
    "    sets = [\"training\", \"validation\", \"testing\"]\n",
    "    for x in mods:\n",
    "        for y in sets:\n",
    "            input_dir = os.path.join(base_dir, x, y)\n",
    "\n",
    "            files = os.listdir(input_dir)\n",
    "\n",
    "            for f in tqdm(files, desc=f\"Processing {x}\"):\n",
    "                input_file_path = os.path.join(input_dir, f)\n",
    "\n",
    "                img_nifti = nib.load(input_file_path)\n",
    "                img_data = img_nifti.get_fdata()  # Shape: (height, width, depth)\n",
    "\n",
    "                # Adjust dimensions for T1 modality to match others\n",
    "                if x == \"IXI-T1\":\n",
    "                    img_data = np.transpose(img_data, (2, 0, 1))  # Adjusted reshuffling\n",
    "\n",
    "                depth_total = img_data.shape[2]  # z direction after alignment\n",
    "\n",
    "                mid = random.randint(30, 90)  # Random slice between 30 and 90\n",
    "                start_slice = max(0, mid - 3)\n",
    "                end_slice = min(depth_total, mid + 3)\n",
    "\n",
    "                middle_slices = img_data[:, :, start_slice:end_slice]\n",
    "\n",
    "                middle_img_nifti = nib.Nifti1Image(middle_slices, affine=img_nifti.affine, header=img_nifti.header)\n",
    "\n",
    "                nib.save(middle_img_nifti, input_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f948d-f6b1-4dad-8f7a-0a3e3201c7e8",
   "metadata": {},
   "source": [
    "## Rician Noise Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579df818-12fd-49de-be0a-318761061a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rice_noise(img, snr=10, mu=0.0, sigma=1): #adds rician noise to the data\n",
    "    level = snr * np.max(img) / 100 #(snr - signal to noise ratio)\n",
    "    size = img.shape\n",
    "    x = level * np.random.normal(mu, sigma, size=size) + img #real noise\n",
    "    y = level * np.random.normal(mu, sigma, size=size) #imaginary noise\n",
    "    #return np.sqrt(x**2 + y**2).astype(np.int16) #magnitude of noise\n",
    "    return np.sqrt(x**2 + y**2).astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542423ac-3916-44b2-8af8-8a41bcf72205",
   "metadata": {},
   "source": [
    "## Function that Applies Noise to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13218958-f1a2-4304-b124-910d2f41e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noised_mri():\n",
    "    base_dir = \"./data/dataset/Free/\"\n",
    "    mods = [\"IXI-T1\",\"IXI-T2\",\"IXI-PD\"]  # Modalities\n",
    "    sets = [\"training\",\"validation\",\"testing\"] \n",
    "    levels = [1, 7, 13]\n",
    "    for m in levels:\n",
    "        for x in mods:\n",
    "            for y in sets:\n",
    "                input_dir = os.path.join(base_dir, x, y)\n",
    "                output_dir = \"./data/dataset/noise_{}/{}/{}\".format(m, x, y)\n",
    "        \n",
    "                if not os.path.exists(output_dir):#Create the output directory if DNE \n",
    "                    os.makedirs(output_dir)\n",
    "\n",
    "                files = [f for f in os.listdir(input_dir)]\n",
    "                        \n",
    "                for file in tqdm(files, desc=f\"Processing {x}\"): #cool time module that shows the status bar\n",
    "                    nii_img = nib.load(os.path.join(input_dir, file))\n",
    "                    free_image = nii_img.get_fdata()  #Load  MRI image data\n",
    "                    noised_image = add_rice_noise(free_image, snr=m)\n",
    "                    noised_image = nib.Nifti1Image(noised_image, nii_img.affine, nii_img.header)\n",
    "                    nib.save(noised_image, os.path.join(output_dir, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17802659-57c9-49d7-a7f4-643a15becac1",
   "metadata": {},
   "source": [
    "## Patch Generator for Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341bf067-0d2b-41f7-bfb5-013620450301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patch():\n",
    "    stride = 16\n",
    "    ## potentially stride = size / 2\n",
    "    size = 32\n",
    "    depth = 6\n",
    "\n",
    "    base_dir = \"./data/dataset/Free/\"\n",
    "    mods = [\"IXI-T1\",\"IXI-T2\",\"IXI-PD\"]  # Modalities\n",
    "    sets = [\"training\",\"validation\",\"testing\"]\n",
    "    levels = [1, 7, 13]\n",
    "    \n",
    "    for n in levels:\n",
    "        for x in mods:\n",
    "            for d in sets:\n",
    "                input_free_dir = os.path.join(base_dir, x, d)\n",
    "                input_noised_dir = os.path.join(\"./data/dataset/noise_%s\" % n, x, d)\n",
    "                output_free_dir = os.path.join(\"./data/patchs32_32_%s/free\" % n, x, d)\n",
    "                output_noised_dir = os.path.join(\"./data/patchs32_32_%s/noised\" % n, x, d)\n",
    "\n",
    "                # Create output directories if they don't exist\n",
    "                if not os.path.exists(output_free_dir):\n",
    "                    os.makedirs(output_free_dir)\n",
    "                if not os.path.exists(output_noised_dir):\n",
    "                    os.makedirs(output_noised_dir)\n",
    "\n",
    "                files = [f for f in os.listdir(input_free_dir)]\n",
    "\n",
    "                for file in tqdm(files, desc=f\"Processing {x} for Level {n}\"):\n",
    "                    free_img_path = os.path.join(input_free_dir, file)\n",
    "                    noised_img_path = os.path.join(input_noised_dir, file)\n",
    "\n",
    "                    free_img = nib.load(free_img_path).get_fdata()\n",
    "                    noised_img = nib.load(noised_img_path).get_fdata()\n",
    "\n",
    "                    free_img_set = None\n",
    "                    noised_img_set = None\n",
    "    \n",
    "                    height, width, _ = free_img.shape\n",
    "\n",
    "                    for y in range(0, height - size + 1, stride):\n",
    "                        for x_pos in range(0, width - size + 1, stride):\n",
    "                            free_img_temp = free_img[y:y+size, x_pos:x_pos+size, :].copy().transpose(2, 0, 1)\n",
    "                            noised_img_temp = noised_img[y:y+size, x_pos:x_pos+size, :].copy().transpose(2, 0, 1)\n",
    "\n",
    "                            # Reshape to (1, 1, depth, size, size)\n",
    "                            free_img_temp = np.reshape(free_img_temp, (1, 1, depth, size, size))\n",
    "                            noised_img_temp = np.reshape(noised_img_temp, (1, 1, depth, size, size))\n",
    "\n",
    "                            if free_img_set is None:\n",
    "                                free_img_set = free_img_temp\n",
    "                                noised_img_set = noised_img_temp\n",
    "                            else:\n",
    "                                free_img_set = np.append(free_img_set, free_img_temp, axis=0)\n",
    "                                noised_img_set = np.append(noised_img_set, noised_img_temp, axis=0)\n",
    "\n",
    "                    \n",
    "                    root1 = os.path.splitext(os.path.splitext(os.path.basename(free_img_path))[0])[0]\n",
    "                    root2 = os.path.splitext(os.path.splitext(os.path.basename(noised_img_path))[0])[0]\n",
    "                    \n",
    "                    np.save(os.path.join(output_free_dir, root1 + f\"-{n}\" + \".npy\"), free_img_set)\n",
    "                    np.save(os.path.join(output_noised_dir, root2 + f\"-{n}\" + \".npy\"), noised_img_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785cf622-6e13-4128-9e87-919d2d0ecb1a",
   "metadata": {},
   "source": [
    "## Mix the Data and Combine the Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d5f20-eaae-494c-b58d-986a3299bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_patches():\n",
    "    levels = [1, 7, 13] \n",
    "    categories = ['free', 'noised']\n",
    "    mods = [\"IXI-PD\"]\n",
    "    sets = [\"training\", \"validation\", \"testing\"]\n",
    "    mixdata_dir = \"./data/mixdata/\"\n",
    "\n",
    "    for mod in mods:\n",
    "        for data_set in sets:\n",
    "            free_patches = []\n",
    "            noised_patches = []\n",
    "            free_patch_names = [] \n",
    "            noised_patch_names = [] \n",
    "\n",
    "            for level in levels:\n",
    "                free_dir = f\"./data/patchs32_32_{level}/free/{mod}/{data_set}\"\n",
    "                noised_dir = f\"./data/patchs32_32_{level}/noised/{mod}/{data_set}\"\n",
    "\n",
    "                free_files = sorted([f for f in os.listdir(free_dir)])\n",
    "                noised_files = sorted([f for f in os.listdir(noised_dir)])\n",
    "                \n",
    "                for patch_file in tqdm(free_files, desc=f\"    Loading patches for noise level {level} in {data_set} set\"):\n",
    "                    free_patch_path = os.path.join(free_dir, patch_file)\n",
    "                    noised_patch_path = os.path.join(noised_dir, patch_file)\n",
    "                    \n",
    "                    # loading data\n",
    "                    # TODO: move out of for loops\n",
    "                    free_patch = np.load(free_patch_path)\n",
    "                    noised_patch = np.load(noised_patch_path)\n",
    "\n",
    "                    if free_patch.ndim > 1 and free_patch.shape[0] > 1:\n",
    "                        # If the first dimension represents multiple patches, iterate and append names accordingly\n",
    "                        for i in range(free_patch.shape[0]):\n",
    "                            free_patches.append(free_patch[i])\n",
    "                            noised_patches.append(noised_patch[i])\n",
    "                            free_patch_names.append(f\"{patch_file}_patch{i}\")\n",
    "                            noised_patch_names.append(f\"{patch_file}_patch{i}\")\n",
    "                    else:\n",
    "                        # Single patch per file\n",
    "                        free_patches.append(free_patch)\n",
    "                        noised_patches.append(noised_patch)\n",
    "                        free_patch_names.append(patch_file)\n",
    "                        noised_patch_names.append(patch_file)\n",
    "\n",
    "            free_array = np.concatenate(free_patches, axis=0)  # Shape: (num_patches, 1, 6, 32, 32)\n",
    "            noised_array = np.concatenate(noised_patches, axis=0)\n",
    "\n",
    "            #print(f\"# of free patches: {free_array.shape[0]}; # of free patch names: {len(free_patch_names)} \") #validation\n",
    "            #print(f\"# of noised patches: {noised_array.shape[0]}; # of noised patch names: {len(noised_patch_names)}\")\n",
    "\n",
    "            indices = np.arange(free_array.shape[0])\n",
    "            np.random.shuffle(indices)\n",
    "            free_shuffled = free_array[indices]\n",
    "            noised_shuffled = noised_array[indices]\n",
    "\n",
    "            free_shuffled_names = [free_patch_names[i] for i in indices]\n",
    "            noised_shuffled_names = [noised_patch_names[i] for i in indices]\n",
    "            numbered_free_names = {i: name for i, name in enumerate(free_shuffled_names)} # Create a mapping from index to patch name\n",
    "            numbered_noised_names = {i: name for i, name in enumerate(noised_shuffled_names)}\n",
    "            \n",
    "            output_free_dir = os.path.join(mixdata_dir, 'free', mod, data_set)\n",
    "            output_noised_dir = os.path.join(mixdata_dir, 'noised', mod, data_set)\n",
    "            os.makedirs(output_free_dir, exist_ok=True)\n",
    "            os.makedirs(output_noised_dir, exist_ok=True)\n",
    "\n",
    "            free_output_path = os.path.join(output_free_dir, \"combined_free.npy\")\n",
    "            noised_output_path = os.path.join(output_noised_dir, \"combined_noised.npy\")\n",
    "            \n",
    "            # TODO: move out of for loops\n",
    "            np.save(free_output_path, free_shuffled)\n",
    "            np.save(noised_output_path, noised_shuffled)\n",
    "            \n",
    "            #print(f\"    Saved combined and shuffled free patches at '{free_output_path}' with shape {free_shuffled.shape}\")\n",
    "            #print(f\"    Saved combined and shuffled noised patches at '{noised_output_path}' with shape {noised_shuffled.shape}\\n\")\n",
    "\n",
    "            free_names_path = os.path.join(output_free_dir, \"free_patch_names.json\")\n",
    "            noised_names_path = os.path.join(output_noised_dir, \"noised_patch_names.json\")\n",
    "\n",
    "            # TODO: move out of for loops\n",
    "            with open(free_names_path, 'w') as f:\n",
    "                json.dump(numbered_free_names, f, indent=4)\n",
    "            with open(noised_names_path, 'w') as f:\n",
    "                json.dump(numbered_noised_names, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f24a09-370f-4a56-836c-98c9ac6d3f42",
   "metadata": {},
   "source": [
    "## Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ba10f-53b2-41e6-97a5-ab73c90c87bf",
   "metadata": {},
   "source": [
    "Testing phase to process new images after the model has been trained (Evaluate model performance on full images; generate output images). The patch test image function is used to extract patches from the test image.  When it extracts patches, it keeps track of their positions in the original image, which is necessary for accurate reconstruction (unlike generate_patch). The merge function combines the processed patches from the model back into a seamless image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804a7c1-e8af-4e21-9748-5bc7c3cf8a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_test_img(img, size=32):\n",
    "    patchs = []\n",
    "    height, width, depth = img.shape\n",
    "    \n",
    "    row = 0\n",
    "                            \n",
    "    for i in range(0, height-size+1, size//2):\n",
    "        row += 1\n",
    "        col = 0\n",
    "        for j in range(0, width-size+1, size//2):\n",
    "            col += 1\n",
    "            patchs.append(img[i:i+size, j:j+size,:])\n",
    "    temp = np.vstack(patchs)\n",
    "    temp = np.reshape(temp, (-1, size, size, depth))\n",
    "    return temp, row, col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52adc12-d547-44ef-b841-0cc42423c991",
   "metadata": {},
   "source": [
    "Averages overlapping regions to ensure smooth transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e091ef15-ee9c-4f78-9338-655c585d1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_test_img(patchs, row, col,size=32):\n",
    "    \n",
    "    patchs_num = patchs.shape[0]\n",
    "    num = int(math.sqrt(patchs_num))\n",
    "    rows = []\n",
    "    x = size // 8\n",
    "    y = size//4\n",
    "    row_index = 0\n",
    "    for i in range(0, patchs_num, col):\n",
    "        temp = patchs[i,:,:-x,:]\n",
    "        for j in range(1, col - 1):\n",
    "            temp[:, -y:, :] = (temp[ :, -y:, :] + patchs[i+j, :,x:x+y,:]) / 2\n",
    "            temp = np.append(temp, patchs[i + j, :, x+y:-x, :], axis=1)\n",
    "        temp[:, -y:, :] = (temp[:, -y:, :] + patchs[i+j+1, :,x:x+y,:]) / 2\n",
    "        temp = np.append(temp, patchs[i + j+1, :, x+y:, :], axis=1)\n",
    "        \n",
    "        a = row_index * 16\n",
    "        b = row_index * 16 + 32\n",
    "        row_index += 1\n",
    "        rows.append(temp)\n",
    "    img = rows[0][:-x,:,:]\n",
    "    length = len(rows)\n",
    "    for i in range(1, length-1):\n",
    "        height = img.shape[0]\n",
    "        img[-y:, :, :] = (img[-y:, :, :] + rows[i][x:x+y, :, :])/2\n",
    "        img = np.append(img, rows[i][x+y:-x, :, :], axis=0)\n",
    "    img[-y:, :, :] = (img[ -y:, :, :] + rows[-1][x:x+y, :, :]) / 2\n",
    "    img = np.append(img, rows[-1][ x+y:, :, :], axis=0)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae38268-5b6e-4aaa-96c4-21d82ba5add9",
   "metadata": {},
   "source": [
    "## Executable Block for Hammer Smith (70% training, 10% validation, 20% testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a636c03-35c5-41a1-8edb-7b051f220c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": #, Python sets __name__ to \"__main__\"\n",
    "    hammer_mri(14,2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7a874b-92b2-4243-9c8c-b0294c5541bd",
   "metadata": {},
   "source": [
    "## Executable for 6 Deep Data (Make Sure to Eliminate File #IXI163(Corrupted) for both PD and T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3acffb6-e6fb-4b69-9bea-597bdb25080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    extract_mid_slices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b8d16-982b-4dff-87fc-aee340f91413",
   "metadata": {},
   "source": [
    "## Executable Block for Noisy Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adac82c-6932-4d82-bb87-d0fe2bd3fbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "        generate_noised_mri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f8af1-2f61-4cc4-ab80-cb89c63f04f9",
   "metadata": {},
   "source": [
    "## Executable Block for Patched Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42901609-b000-450a-91a0-2a14fc26bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": #, Python sets __name__ to \"__main__\"\n",
    "    generate_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d4732c-7b26-48c4-bdb5-3f8891bcae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    combine_patches()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38669607-49e3-4a89-97ca-081bcd62e4c6",
   "metadata": {},
   "source": [
    "## Patch Test (Put in file path and index to view respective patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ab989-5c0b-4c26-a6f9-3593f1539a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_file_path = '/Users/john_1john_1/Library/CloudStorage/OneDrive-UniversityofNorthCarolinaatChapelHill/MRI-Denoising-Project/data/patchs32_32_13/free/IXI-PD/testing/IXI176-HH-1604-PD-13.npy' \n",
    "\n",
    "patch_index = 600 \n",
    "\n",
    "patches = np.load(patches_file_path)\n",
    "num_patches = patches.shape[0]\n",
    "\n",
    "if patch_index < 0 or patch_index >= num_patches:\n",
    "    print(f\"Patch index {patch_index} is out of bounds. Number of patches: {num_patches}\")\n",
    "else:\n",
    "    patch = patches[patch_index]\n",
    "\n",
    "    print(f\"Patch {patch_index} shape: {patch.shape}\")\n",
    "\n",
    "    # If the patch has a singleton dimension for channels, remove it\n",
    "    if patch.shape[0] == 1:\n",
    "        patch = np.squeeze(patch, axis=0)  # Now shape is (depth, height, width)\n",
    "\n",
    "    # Display each depth slice in the patch\n",
    "    depth = patch.shape[0]\n",
    "    for i in range(depth):\n",
    "        plt.imshow(patch[i], cmap='gray')\n",
    "        plt.title(f'Patch {patch_index}, Depth Slice {i}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64482a2-bed8-4442-93d6-7bf76480641c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
